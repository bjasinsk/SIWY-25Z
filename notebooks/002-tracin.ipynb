{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fc638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm.auto import tqdm\n",
    "from TracInPyTorch.src.tracin import vectorized_calculate_tracin_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d52c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"D:\\SIWY\\SIWY-25Z-Jarczewski-Rozej-Jasinski\\data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c15283",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0388aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mul(torch.nn.Module):\n",
    "    def __init__(self, weight):\n",
    "        super(Mul, self).__init__()\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.weight\n",
    "\n",
    "\n",
    "class Flatten(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "\n",
    "class Residual(torch.nn.Module):\n",
    "    def __init__(self, module):\n",
    "        super(Residual, self).__init__()\n",
    "        self.module = module\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.module(x)\n",
    "\n",
    "\n",
    "def construct_rn9(num_classes=10):\n",
    "    def conv_bn(channels_in, channels_out, kernel_size=3, stride=1, padding=1, groups=1):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(\n",
    "                channels_in,\n",
    "                channels_out,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                groups=groups,\n",
    "                bias=False,\n",
    "            ),\n",
    "            torch.nn.BatchNorm2d(channels_out),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    model = torch.nn.Sequential(\n",
    "        conv_bn(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "        conv_bn(64, 128, kernel_size=5, stride=2, padding=2),\n",
    "        Residual(torch.nn.Sequential(conv_bn(128, 128), conv_bn(128, 128))),\n",
    "        conv_bn(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "        torch.nn.MaxPool2d(2),\n",
    "        Residual(torch.nn.Sequential(conv_bn(256, 256), conv_bn(256, 256))),\n",
    "        conv_bn(256, 128, kernel_size=3, stride=1, padding=0),\n",
    "        torch.nn.AdaptiveMaxPool2d((1, 1)),\n",
    "        Flatten(),\n",
    "        torch.nn.Linear(128, num_classes, bias=False),\n",
    "        Mul(0.2),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e3187f",
   "metadata": {},
   "source": [
    "### DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a70bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(batch_size=256, num_workers=8, split=\"train\", shuffle=False, augment=True):\n",
    "    if augment:\n",
    "        transforms = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.Resize(256),\n",
    "                torchvision.transforms.CenterCrop(224),\n",
    "                torchvision.transforms.RandomHorizontalFlip(),\n",
    "                torchvision.transforms.RandomAffine(0),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.201)),\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        transforms = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.Resize(256),\n",
    "                torchvision.transforms.CenterCrop(224),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.201)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    is_train = split == \"train\"\n",
    "    # dataset = torchvision.datasets.CIFAR10(root='/tmp/cifar/',\n",
    "    #                                        download=True,\n",
    "    #                                        train=is_train,\n",
    "    #                                        transform=transforms)\n",
    "    if is_train:\n",
    "        dataset = ImageFolder(root=Path(f\"{DATA_DIR}/task1/task1/easy/train\"), transform=transforms)\n",
    "    else:\n",
    "        dataset = ImageFolder(root=Path(f\"{DATA_DIR}/task1/task1/easy/val\"), transform=transforms)\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset, shuffle=shuffle, batch_size=batch_size, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ede2845",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b61fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model, loader, lr=0.4, epochs=24, momentum=0.9, weight_decay=5e-4, lr_peak_epoch=5, label_smoothing=0.0, model_id=0\n",
    "):\n",
    "    opt = SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    iters_per_epoch = len(loader)\n",
    "    # Cyclic LR with single triangle\n",
    "    lr_schedule = np.interp(\n",
    "        np.arange((epochs + 1) * iters_per_epoch),\n",
    "        [0, lr_peak_epoch * iters_per_epoch, epochs * iters_per_epoch],\n",
    "        [0, 1, 0],\n",
    "    )\n",
    "    scheduler = lr_scheduler.LambdaLR(opt, lr_schedule.__getitem__)\n",
    "    scaler = GradScaler()\n",
    "    loss_fn = CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        print(ep)\n",
    "        for it, (ims, labs) in enumerate(loader):\n",
    "            ims = ims.cuda()\n",
    "            labs = labs.cuda()\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with autocast():\n",
    "                out = model(ims)\n",
    "                loss = loss_fn(out, labs)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "        if ep in [12, 15, 18, 21, 23]:\n",
    "            torch.save(model.state_dict(), f\"{DATA_DIR}/checkpoints-2cls/sd_{model_id}_epoch_{ep}.pt\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_criterion(model, lr, momentum=0.9, weight_decay=5e-4):\n",
    "    return SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad66b94",
   "metadata": {},
   "source": [
    "### MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648e34d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "# train_dataset = ImageFolder(root=f'{DATA_DIR}/task1/task1/easy/train', transform=transform)\n",
    "# val_dataset = ImageFolder(root=f'{DATA_DIR}/task1/task1/easy/val', transform=transform)\n",
    "\n",
    "\n",
    "os.makedirs(f\"{DATA_DIR}/checkpoints-2cls\", exist_ok=True)\n",
    "loader_for_training = get_dataloader(batch_size=128, split=\"train\", shuffle=True)\n",
    "\n",
    "# you can modify the for loop below to train more models\n",
    "for i in tqdm(range(1), desc=\"Training models..\"):\n",
    "    model = construct_rn9(2).to(memory_format=torch.channels_last).cuda()\n",
    "    model = train(model, loader_for_training, model_id=i)\n",
    "\n",
    "ckpt_files = sorted(list((DATA_DIR / Path(\"./checkpoints-2cls\")).rglob(\"*.pt\")))\n",
    "# ckpts = [torch.load(ckpt), map_location='cpu' for ckpt in ckpt_files]\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "model = construct_rn9(2)\n",
    "criterion = CrossEntropyLoss(label_smoothing=0.0)\n",
    "# create_criterion(model, lr=0.4, momentum=0.9, weight_decay=5e-4)\n",
    "weights = ckpt_files\n",
    "train_loader = get_dataloader(batch_size=batch_size, split=\"train\")\n",
    "test_loader = get_dataloader(batch_size=batch_size, split=\"val\", augment=False)\n",
    "lr = 0.4\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "print(\"len test loader:\", len(test_loader.dataset))\n",
    "use_nested_loop_for_dot_product = False  # via einsum\n",
    "float_labels = False  # depends on your loss function\n",
    "\n",
    "\n",
    "matrix = vectorized_calculate_tracin_score(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    weights_paths=weights,\n",
    "    train_dataloader=train_loader,\n",
    "    test_dataloader=test_loader,\n",
    "    lr=lr,\n",
    "    device=device,\n",
    "    use_nested_loop_for_dot_product=use_nested_loop_for_dot_product,\n",
    "    float_labels=float_labels,\n",
    ")\n",
    "\n",
    "print(\"TracIn Score Matrix shape:\", matrix.shape)\n",
    "matrix_path = DATA_DIR / \"tracin_score_matrix.pt\"\n",
    "torch.save(matrix_path, matrix)\n",
    "print(f\"TracIn Score Matrix saved at: {matrix_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
